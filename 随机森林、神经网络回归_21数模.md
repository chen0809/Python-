[TOC]



# 变量相关性可视化

```python
import seaborn as sns
df= features.loc[:,names[:20]]
dfData = df.corr()
plt.subplots(figsize=(20, 20)) # 设置画面大小
sns.heatmap(dfData, cmap="RdBu", 
            annot=True, annot_kws={"size":15})  # annot:添加相关程度

ax=plt.gca()
plt.tick_params(labelsize=15)
labels = ax.get_xticklabels() + ax.get_yticklabels()

cax = plt.gcf().axes[-1]
cax.tick_params(labelsize=15)

plt.savefig('相关系数热力图.jpg')
plt.show()
```

![](C:\Users\10630\Desktop\下载.png)



# 随机森林回归+特征提取

## 训练模型

```python
# 加载库
from sklearn.ensemble import RandomForestRegressor

# 建立自变量与应变量
features = new_qsar_d.iloc[: ,2:]
target = new_qsar_d.iloc[:,1]

# 创建随机森林回归对象
randomforest = RandomForestRegressor(random_state=0, n_jobs=-1)

# 训练模型
model = randomforest.fit(features, target)
```

## 特征重要性&可视化

```python
# 计算特征的重要性
importances = model.feature_importances_

impt = pd.DataFrame()
impt['features'] = new_qsar_d.columns[2:]
impt['importance'] = importances
impt.head()

# 将特征的重要性按降序排列
indices = np.argsort(importances)[::-1]

# 按照特征的重要性对特征名称重新排序
names = [new_qsar_d.columns[2:][i] for i in indices]

# 创建图
plt.figure(figsize = (10,10))

# 创建图标题
plt.title("变量重要性", size=15)

# 添加数据条
plt.bar(range(20), importances[indices][:20])

# 将特征名称添加为 x 轴标签
plt.xticks(range(20), names[:20], rotation=90)

ax=plt.gca()
plt.tick_params(labelsize=15)
# plt.xticks(rotation = 15) 
labels = ax.get_xticklabels() + ax.get_yticklabels()

plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号

# 显示图
plt.show()


```

## 模型评价

```python
result = model.predict(features)
ResidualSquare = (result - target)**2     #计算残差平方
RSS = sum(ResidualSquare)   #计算残差平方和
MSE = np.mean(ResidualSquare)   #计算均方差
TSS = sum((target - np.mean(target))**2)
num_regress = len(result)   #回归样本个数
R2 = 1-(RSS/TSS) # 拟合优度
R2_ba = 1-(1-R2)*1973/(1973-239)

print(f'n={num_regress}')
print(f'MSE={MSE}')
print(f'RSS={RSS}')
print(R2_ba)

# 交叉验证均方误差
from sklearn.model_selection import cross_val_score

cv_mse = cross_val_score(model, features, target, scoring='neg_mean_squared_error', cv=10)
print(np.mean(cv_mse), cv_mse) # 均方误差
```

## 选择模型变量

```python
cv_mse_mean = []
for i in range(1, 21):
    features_train = features.loc[:, names[:i]]
    
    # 创建随机森林回归对象
    randomforest = RandomForestRegressor(random_state=0, n_jobs=-1)

    # 训练模型
    model_train = randomforest.fit(features_train, target)
    
    cv_mse = cross_val_score(model_train, features_train, target, scoring='neg_mean_squared_error', cv=10)
    cv_mse_mean.append(np.mean(cv_mse))

cv_mse_mean

# 可视化
import matplotlib.pyplot as plt
from matplotlib.pyplot import MultipleLocator

plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号

x = range(1, 21)
y = cv_mse_mean * np.ones(20)*(-1)

plt.figure(figsize=(10, 6))
plt.xlabel('引入变量数', size=15)
plt.ylabel('均方误差', size=15)# 通过 xlabel 和 ylabel 来设置轴的名称
plt.plot(x, y)
plt.title('不同变量数对模型MSE的影响',size=15)

ax=plt.gca()
x_major_locator=MultipleLocator(1)
ax.xaxis.set_major_locator(x_major_locator)

plt.tick_params(labelsize=15)
labels = ax.get_xticklabels() + ax.get_yticklabels()

# 画出标注点
plt.scatter(8, -cv_mse_mean[7], s=15, c='red')
plt.annotate('最佳变量数', xy=(8, -cv_mse_mean[7]),# 标注的内容
             xycoords='data',# 基于数据的值来选位置
             xytext=(0, +50),# 对于标注位置的描述 和 xy 偏差值，即标注位置是 xy 位置向右移动 30，向下移动30
             textcoords='offset points', fontsize=15,
             arrowprops=dict(arrowstyle='->', connectionstyle="arc3,rad=.2"))# 对图中箭头类型、弧度、颜色的设置

plt.show()

names[:8]
```

![](C:\Users\10630\Desktop\下载 (1).png)

## 重新建立模型

```python
# 加载库
from sklearn.tree import DecisionTreeRegressor
from sklearn import datasets

# 建立自变量与应变量
features = new_qsar_d.iloc[: ,2:]
target = new_qsar_d.iloc[:,1]

# 将特征的重要性按降序排列
indices = np.argsort(importances)[::-1]

# 按照特征的重要性对特征名称重新排序
names = [new_qsar_d.columns[2:][i] for i in indices]

features_train = features.loc[:, names[:8]]

# 创建随机森林回归对象
randomforest = RandomForestRegressor(random_state=0, n_jobs=-1)

# 训练模型
model_train = randomforest.fit(features_train, target)

result = model_train.predict(features_train)
ResidualSquare = (result - target)**2     #计算残差平方
RSS = sum(ResidualSquare)
MSE = np.mean(ResidualSquare)   #计算均方差
num_regress = len(result)   #回归样本个数
TSS = sum((target - np.mean(target))**2)
R2 = 1-(RSS/TSS) # 拟合优度
R2_ba = 1-(1-R2)*1973/(1973-8)

print(f'n={num_regress}')
print(f'MSE={MSE}')
print('R^2 = ',R2_ba)
```

## 交叉验证曲线

```python
from sklearn.model_selection import learning_curve

cv_mse = cross_val_score(randomforest, features_train, target, scoring='neg_mean_squared_error', cv=10)

train_mean = np.ones(10)*-np.mean(cv_mse)
train_std = np.ones(10)*np.std(cv_mse)
train_scores =np.ones(10)*-1 * cv_mse

plt.figure(figsize=(10,6))

# 画线
plt.plot(range(1,11), train_mean , '--', color="#111111", label="平均MSE")
plt.plot(range(1,11), train_scores, color="#111111", label="MSE")

# 画带状图
plt.fill_between(range(1,11), train_scores - train_std, train_scores + train_std, color="#DDDDDD")

# 创建图
plt.title("交叉验证曲线",size=15)
plt.xlabel("训练次数", size=15)
plt.ylabel("均方误差", size=15),
plt.legend(loc="best")
plt.tight_layout()

plt.tick_params(labelsize=15)
labels = ax.get_xticklabels() + ax.get_yticklabels()

ax=plt.gca()
x_major_locator=MultipleLocator(1)
ax.xaxis.set_major_locator(x_major_locator)

plt.show()
```

![](C:\Users\10630\Desktop\下载 (2).png)

##预测

```python
# 将特征的重要性按降序排列
indices = np.argsort(importances)[::-1]

# 按照特征的重要性对特征名称重新排序
names = [new_qsar_d.columns[2:][i] for i in indices]

# 建立自变量与应变量
features_test = m_d_test.loc[:, names[:8]]

# 预测
model_test = model_train.predict(features_test)
```



# 神经网络回归

## 训练模型

```python
# 加载库
from keras.preprocessing.text import Tokenizer
from keras import models
from keras import layers
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.preprocessing import StandardScaler

# 设置随机种子
np.random.seed(0)

def create_network():

    # 启动神经网络
    network = models.Sequential()

    # 添加使用 ReLU 激活函数的全连接层
    network.add(layers.Dense(units = features.shape[1],
                             activation="relu",
                             input_shape=(features.shape[1],)))

    # 添加使用 ReLU 激活函数的全连接层
    network.add(layers.Dense(units=features.shape[1], activation="relu"))

    # 添加没有激活函数的全连接层
    network.add(layers.Dense(units=1))

    # 编译神经网络
    network.compile(loss="mse", # 均方误差
                    optimizer="RMSprop", # 优化算法
                    metrics=["mse"]) # 均方误差
    return network

# 标准化特征
scaler = StandardScaler()
features_standardized = scaler.fit_transform(features)


# 封装神经网络
neural_network =KerasRegressor(build_fn=create_network, epochs=10, batch_size=100, verbose=0)

# 训练
cv_mse = cross_val_score(neural_network, features_standardized, target, scoring='neg_mean_squared_error', cv=10)
print(np.mean(cv_mse), cv_mse) # 均方误差
```



## 模型评价

```python
network = create_network()
result = network.predict(features_standardized)
ResidualSquare = (result.reshape(1974) - target)**2     #计算残差平方
RSS = sum(ResidualSquare)   #计算残差平方和
MSE = np.mean(ResidualSquare)   #计算均方差
TSS = sum((target - np.mean(target))**2)
R2 = 1-(RSS/TSS) # 拟合优度
R2_ba = 1-(1-R2)*1973/(1973-features.shape[1])
print('MSE = ', MSE)
print(R2_ba)
```

